{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration (ms)</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195000</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-8.815</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.520</td>\n",
       "      <td>128.050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194641</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-6.848</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.250</td>\n",
       "      <td>122.985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217573</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-8.029</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.247</td>\n",
       "      <td>170.044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443478</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-4.571</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.199</td>\n",
       "      <td>92.011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225862</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-5.863</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.163</td>\n",
       "      <td>115.917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration (ms)  danceability  energy  loudness  speechiness  acousticness  \\\n",
       "0         195000         0.611   0.614    -8.815       0.0672        0.0169   \n",
       "1         194641         0.638   0.781    -6.848       0.0285        0.0118   \n",
       "2         217573         0.560   0.810    -8.029       0.0872        0.0071   \n",
       "3         443478         0.525   0.699    -4.571       0.0353        0.0178   \n",
       "4         225862         0.367   0.771    -5.863       0.1060        0.3650   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  labels  \n",
       "0          0.000794    0.7530    0.520  128.050       2  \n",
       "1          0.009530    0.3490    0.250  122.985       1  \n",
       "2          0.000008    0.2410    0.247  170.044       1  \n",
       "3          0.000088    0.0888    0.199   92.011       0  \n",
       "4          0.000001    0.0965    0.163  115.917       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus_df = pd.read_csv(\"archive/278k_song_labelled.csv\")\n",
    "mus_df = mus_df.drop(columns=[\"song_number\", \"spec_rate\"])\n",
    "mus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration (ms)</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195000</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-8.815</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.520</td>\n",
       "      <td>128.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194641</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-6.848</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.250</td>\n",
       "      <td>122.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217573</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-8.029</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.247</td>\n",
       "      <td>170.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443478</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-4.571</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.199</td>\n",
       "      <td>92.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225862</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-5.863</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.163</td>\n",
       "      <td>115.917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration (ms)  danceability  energy  loudness  speechiness  acousticness  \\\n",
       "0         195000         0.611   0.614    -8.815       0.0672        0.0169   \n",
       "1         194641         0.638   0.781    -6.848       0.0285        0.0118   \n",
       "2         217573         0.560   0.810    -8.029       0.0872        0.0071   \n",
       "3         443478         0.525   0.699    -4.571       0.0353        0.0178   \n",
       "4         225862         0.367   0.771    -5.863       0.1060        0.3650   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  \n",
       "0          0.000794    0.7530    0.520  128.050  \n",
       "1          0.009530    0.3490    0.250  122.985  \n",
       "2          0.000008    0.2410    0.247  170.044  \n",
       "3          0.000088    0.0888    0.199   92.011  \n",
       "4          0.000001    0.0965    0.163  115.917  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = mus_df[\"labels\"]\n",
    "data = mus_df.drop(columns=\"labels\")\n",
    "data.head()\n",
    "# print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9381281331702286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     24562\n",
      "           1       0.92      0.95      0.93     32049\n",
      "           2       0.92      0.88      0.90     14068\n",
      "           3       0.97      0.97      0.97     12703\n",
      "\n",
      "    accuracy                           0.94     83382\n",
      "   macro avg       0.94      0.94      0.94     83382\n",
      "weighted avg       0.94      0.94      0.94     83382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data  # Features\n",
    "y = label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Test set accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# # # Convert data to numpy arrays\n",
    "# # X_train_np = np.array(X_train_scaled)\n",
    "# # y_train_np = np.array(y_train)\n",
    "# # X_test_np = np.array(X_test_scaled)\n",
    "# # y_test_np = np.array(y_test)\n",
    "\n",
    "# # # Initialize the TabNet classifier\n",
    "# # tabnet_model = TabNetClassifier(\n",
    "# #     device_name='cpu',  # Use 'cuda' for GPU\n",
    "# #     n_d=8,\n",
    "# #     n_a=8,\n",
    "# #     n_steps=3,\n",
    "# #     gamma=1.3,\n",
    "# #     lambda_sparse=1e-5,\n",
    "# #     optimizer_fn=torch.optim.Adam,\n",
    "# #     optimizer_params=dict(lr=2e-2),\n",
    "# #     scheduler_fn=None,\n",
    "# #     scheduler_params=None,\n",
    "# #     mask_type='entmax',  # Can be 'entmax' or 'sparsemax'\n",
    "# # )\n",
    "\n",
    "# # # Train the model\n",
    "# # tabnet_model.fit(\n",
    "# #     X_train_np, y_train_np,\n",
    "# #     eval_set=[(X_test_np, y_test_np)],\n",
    "# #     eval_name=['test'],\n",
    "# #     eval_metric=['accuracy'],\n",
    "# #     max_epochs=100,\n",
    "# #     patience=10, # controls early stopping \n",
    "# #     batch_size=400,\n",
    "# #     virtual_batch_size=128,  \n",
    "# #     num_workers=0,\n",
    "# #     drop_last=False,\n",
    "# # )\n",
    "# # Assuming you have separate train, validation, and test splits\n",
    "# X_train_np = np.array(X_train_scaled)\n",
    "# y_train_np = np.array(y_train)\n",
    "# X_val_np = np.array(X_val_scaled)\n",
    "# y_val_np = np.array(y_val)\n",
    "# X_test_np = np.array(X_test_scaled)\n",
    "# y_test_np = np.array(y_test)\n",
    "\n",
    "# # Initialize the TabNet classifier\n",
    "# tabnet_model = TabNetClassifier(\n",
    "#     device_name='cpu',\n",
    "#     n_d=8,\n",
    "#     n_a=8,\n",
    "#     n_steps=3,\n",
    "#     gamma=1.3,\n",
    "#     lambda_sparse=1e-5,\n",
    "#     optimizer_fn=torch.optim.Adam,\n",
    "#     optimizer_params=dict(lr=2e-2),\n",
    "#     scheduler_fn=None,\n",
    "#     scheduler_params=None,\n",
    "#     mask_type='entmax',\n",
    "# )\n",
    "\n",
    "# # Train the model with early stopping based on validation set\n",
    "# tabnet_model.fit(\n",
    "#     X_train_np, y_train_np,\n",
    "#     eval_set=[(X_val_np, y_val_np)],  # Use validation set for early stopping\n",
    "#     eval_name=['validation'],\n",
    "#     eval_metric=['accuracy'],\n",
    "#     max_epochs=100,\n",
    "#     patience=0,  # Early stopping patience based on validation set\n",
    "#     batch_size=400,\n",
    "#     virtual_batch_size=128,\n",
    "#     num_workers=0,\n",
    "#     drop_last=False,\n",
    "# )\n",
    "\n",
    "# # After training, you can evaluate on the test set\n",
    "# test_preds = tabnet_model.predict(X_test_np)\n",
    "# test_accuracy = (test_preds == y_test_np).mean()\n",
    "# print(\"Test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict probabilities on the test set\n",
    "# y_pred_probs = tabnet_model.predict_proba(X_test_np)  # Shape (n_samples, num_classes)\n",
    "\n",
    "# # Example: Show probability predictions for the first sample\n",
    "# print(\"Probabilities for each emotion class (sad, happy, energetic, calm):\", y_pred_probs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "X = data  \n",
    "y = label\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9666114988846514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     12338\n",
      "           1       0.96      0.97      0.96     15922\n",
      "           2       0.96      0.94      0.95      7018\n",
      "           3       0.98      0.98      0.98      6413\n",
      "\n",
      "    accuracy                           0.97     41691\n",
      "   macro avg       0.97      0.97      0.97     41691\n",
      "weighted avg       0.97      0.97      0.97     41691\n",
      "\n",
      "Test Accuracy: 0.967187162696985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['music_pred_model\\\\hgb_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb_model = HistGradientBoostingClassifier(\n",
    "    max_iter=300,           \n",
    "    learning_rate=0.1,      \n",
    "    max_depth=None,         \n",
    "    min_samples_leaf=20,    \n",
    "    max_leaf_nodes=31,      \n",
    "    random_state=42,\n",
    "\n",
    ")\n",
    "\n",
    "hgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_val_pred = hgb_model.predict(X_val_scaled)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "y_test_pred = hgb_model.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(hgb_model, 'music_pred_model\\hgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch audio features. Status code: 403\n",
      "{'error': {'status': 403}}\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'rename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m chill_kill_df \u001b[38;5;241m=\u001b[39m get_song_features(chill_kill_url)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(chill_kill_df)\n\u001b[1;32m---> 10\u001b[0m chill_kill_df \u001b[38;5;241m=\u001b[39m \u001b[43mchill_kill_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_ms\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration (ms)\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     11\u001b[0m chill_kill_df \u001b[38;5;241m=\u001b[39m chill_kill_df\u001b[38;5;241m.\u001b[39mloc[:, col_names]\n\u001b[0;32m     13\u001b[0m chill_kill_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(chill_kill_df)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'rename'"
     ]
    }
   ],
   "source": [
    "from spotify_api import get_song_features\n",
    "\n",
    "\n",
    "col_names = data.columns\n",
    "# print(col_names)\n",
    "\n",
    "chill_kill_url = \"https://open.spotify.com/track/68gQG2HpRMxIRom4pCugMq\"\n",
    "chill_kill_df = get_song_features(chill_kill_url)\n",
    "print(chill_kill_df)\n",
    "chill_kill_df = chill_kill_df.rename(columns={'duration_ms': 'duration (ms)'})\n",
    "chill_kill_df = chill_kill_df.loc[:, col_names]\n",
    "\n",
    "chill_kill_scaled = scaler.transform(chill_kill_df)\n",
    "\n",
    "loaded_model = joblib.load('hgb_model.pkl')\n",
    "chill_kill_prediction = loaded_model.predict(chill_kill_scaled)\n",
    "\n",
    "emotions = ['Sad', 'Happy', 'Energetic', 'Calm']\n",
    "print(\"Prediction for 'Chill Kill':\", emotions[chill_kill_prediction[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People can create a personalized music list by providing Spotify links, from which my music emotion classifier will analyze features to predict each song's emotional quality. Additionally, users can take a picture of their surroundings, and my image emotion classifier will determine the mood conveyed in the image. Based on the emotion identified, the system will recommend songs from either the user-provided playlist or a larger music dataset, enhancing the immersive experience of the environment the user is in. The goal of this project is to deepen users' sense of immersion by matching the mood of their surroundings with emotionally resonant music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier for music emotion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the music feature data is tabular, deep learning model might not perform as good as decision tree based model, like random forest and XGBoost. I did experients to compare model performance on the music data On spotify music dataset, including two decision tree based classifier: 1. random forest, 2. XGBoost, and deep learning models: 3. CNN, Tabnet classifier (deep learning model targeted for tabular data, inspired by lightGBM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
